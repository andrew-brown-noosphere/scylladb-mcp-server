#!/usr/bin/env python3
"""ScyllaDB MCP Server with Technical Advisor."""

import os
# Set up cassandra driver for Python 3.13 compatibility BEFORE importing
os.environ['CASS_DRIVER_NO_ASYNCORE'] = '1'
os.environ['CASS_DRIVER_NO_TWISTED'] = '1'
os.environ['CASS_DRIVER_NO_LIBEV'] = '1'

import asyncio
import json
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
import time

import docker
import boto3
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from mcp.server import Server
from mcp.server.models import InitializationOptions
from mcp.server.stdio import stdio_server
from mcp.types import Tool

# Import our technical advisor voice
from technical_advisor import TechnicalAdvisor, technical_response
from query_analyzer import DynamoDBQueryAnalyzer
from scylladb_advisor import ScyllaDBAdvisor
from advanced_cost_calculator import calculate_advanced_cost

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("scylladb-mcp")

@dataclass
class DatabaseConnections:
    """Database connection container."""
    dynamodb: Optional[Any] = None
    scylla: Optional[Any] = None
    alternator: Optional[Any] = None
    docker_container: Optional[Any] = None


class ScyllaDBMCPServer:
    """Main MCP server for ScyllaDB with technical advisor personality."""
    
    def __init__(self):
        self.server = Server(
            name="scylladb-mcp",
            version="1.0.0"
        )
        self.connections = DatabaseConnections()
        self.docker_client = None
        self.advisor = ScyllaDBAdvisor()
        self.technical_advisor = TechnicalAdvisor()
        self.query_analyzer = DynamoDBQueryAnalyzer()
        self._register_tools()
    
    async def create_connections(self):
        """Create database connections based on environment."""
        mode = os.getenv('SCYLLA_MODE', 'docker')
        
        if os.getenv('SCYLLA_IS_DOCKER', 'true').lower() == 'true':
            self.docker_client = docker.from_env()
        
    def _register_tools(self):
        """Register all MCP tools with technical descriptions."""
        
        @self.server.tool()
        async def connect(mode: str = "docker") -> str:
            """
            Connect to ScyllaDB instance (docker, cloud, or both).
            Auto-provisions local Docker container if needed.
            """
            return await self._handle_connect(mode)
        
        @self.server.tool()
        async def execute(query: str, keyspace: str = "demo") -> str:
            """
            Execute CQL query and get performance insights.
            Shows execution time and shard-aware routing benefits.
            """
            return await self._handle_execute(query, keyspace)
        
        @self.server.tool()
        async def checkMigration(code: str, language: str = "python") -> str:
            """
            Check if DynamoDB code is compatible with ScyllaDB Alternator.
            Identifies required changes and estimates migration effort.
            """
            return await self._handle_check_migration(code, language)
        
        @self.server.tool()
        async def analyzeWorkload(code_path: str, deep_analysis: bool = True) -> str:
            """
            Deep analysis of DynamoDB access patterns for migration.
            Detects hot partitions, GSI proliferation, and anti-patterns.
            """
            return await self._handle_analyze_workload(code_path, deep_analysis)
        
        @self.server.tool()
        async def comparePerformance(operation: str, itemCount: int = 1000) -> str:
            """
            Compare ScyllaDB vs DynamoDB performance with real benchmarks.
            Operations: read, write, mixed. Based on scylladb.com data.
            """
            return await self._handle_compare_performance(operation, itemCount)
        
        @self.server.tool()  
        async def costEstimate(reads_per_sec: int, writes_per_sec: int, 
                              storage_gb: int, item_size_kb: float = 1,
                              workload_pattern: str = None,
                              provisioned_capacity: bool = None) -> str:
            """
            Calculate cost comparison between DynamoDB and ScyllaDB.
            Workload patterns: consistent, bursty, read_heavy, write_heavy, time_series.
            Shows real dollar amounts, not percentages.
            """
            return await self._handle_cost_estimate(
                reads_per_sec, writes_per_sec, storage_gb, 
                item_size_kb, workload_pattern, provisioned_capacity
            )
        
        @self.server.tool()
        async def populateData(source: str, table: str = "test_table", rows: int = 1000) -> str:
            """
            Populate test data with realistic patterns.
            Sources: dynamodb_style (hot partitions), ycsb (benchmark).
            """
            return await self._handle_populate_data(source, table, rows)
        
        @self.server.tool()
        async def analyzeDynamoDBModel(data_model: str, requirements: str = None) -> str:
            """
            Analyze AWS DynamoDB data model for ScyllaDB migration.
            Input: DynamoDB model description or AWS blog post content.
            Output: Migration complexity, cost implications, anti-patterns.
            """
            return await self._handle_analyze_dynamodb_model(data_model, requirements)
    
    async def _handle_connect(self, mode: str) -> str:
        """Handle connection with zero-config Docker magic."""
        if mode in ["docker", "both"] and os.getenv('SCYLLA_IS_DOCKER', 'true').lower() == 'true':
            # Check Docker daemon
            try:
                self.docker_client.ping()
            except Exception:
                return technical_response(
                    "Docker daemon not accessible. Start Docker Desktop first.",
                    {'pattern': 'error'}
                )
            
            # Check for existing container
            containers = self.docker_client.containers.list(all=True, filters={"name": "scylladb-mcp"})
            
            if containers:
                container = containers[0]
                if container.status != 'running':
                    logger.info("Starting existing ScyllaDB container...")
                    container.start()
                    self.connections.docker_container = container
                    await self._wait_for_scylla()
                else:
                    logger.info("Using existing running ScyllaDB container")
                    self.connections.docker_container = container
            else:
                # Create new container
                logger.info("Creating new ScyllaDB container...")
                base_response = await self._create_docker_container()
                if "Failed" in base_response:
                    return base_response
                    
                await self._wait_for_scylla()
            
            # Connect via CQL
            try:
                self.connections.scylla = Cluster(['localhost']).connect()
                
                # Create demo keyspace
                self.connections.scylla.execute("""
                    CREATE KEYSPACE IF NOT EXISTS scylladb_demo
                    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}
                """)
                
                base_response = f"‚úÖ Connected to ScyllaDB via Docker\nCreated keyspace: scylladb_demo"
                
            except Exception as e:
                return technical_response(
                    f"Connection failed: {str(e)}", 
                    {'pattern': 'error'}
                )
            
            # Also set up Alternator (DynamoDB API)
            self.connections.alternator = boto3.client(
                'dynamodb',
                endpoint_url='http://localhost:8000',
                region_name='us-east-1',
                aws_access_key_id='fake',
                aws_secret_access_key='fake'
            )
            
            context = {'operation': 'connect', 'is_success': True}
            response = technical_response(base_response, context)
            response += "\n\nAlternator endpoint: http://localhost:8000"
            response += "\nJust change your DynamoDB endpoint URL. Same code, better internals."
            return response
        
        return base_response
    
    async def _handle_execute(self, query: str, keyspace: str = "demo") -> str:
        """Handle CQL query execution with performance insights."""
        if not self.connections.scylla:
            return technical_response(
                "Not connected to ScyllaDB. Run 'connect' first.",
                {'pattern': 'error'}
            )
        
        try:
            # Use keyspace
            self.connections.scylla.execute(f"USE {keyspace}")
            
            # Time the query
            start_time = time.perf_counter()
            result = self.connections.scylla.execute(query)
            execution_time_ms = (time.perf_counter() - start_time) * 1000
            
            # Format results
            rows = []
            for row in result:
                rows.append(dict(row._asdict()))
            
            base_response = f"Query executed in {execution_time_ms:.2f}ms\nRows returned: {len(rows)}\n\n{json.dumps(rows[:10], indent=2, default=str)}"
            
            # Add performance insights based on execution time
            context = {
                'metrics': {'execution_time_ms': execution_time_ms, 'row_count': len(rows)}
            }
            
            if execution_time_ms > 100:
                context['pattern'] = 'slow_query'
                return technical_response(
                    base_response + f"\n\n{execution_time_ms:.0f}ms is slow. Check your partition sizes and query patterns.",
                    context
                )
            elif execution_time_ms < 5 and len(rows) > 0:
                return technical_response(
                    base_response + "\n\nSub-5ms latency. That's shard-aware routing at work.",
                    context
                )
            
            return technical_response(base_response, context)
            
        except Exception as e:
            return technical_response(f"Query failed: {str(e)}", {'pattern': 'error'})
    
    async def _handle_analyze_workload(self, code_path: str, deep_analysis: bool = True) -> str:
        """Analyze DynamoDB workload with deep technical insights."""
        try:
            # Analyze code for DynamoDB patterns
            analysis_results = self.query_analyzer.analyze_repository(code_path)
            
            # Start with summary
            response = f"Analyzed {analysis_results['summary']['total_operations']} DynamoDB operations.\n\n"
            
            # Hot partition analysis
            if analysis_results['hot_partitions']:
                hp = analysis_results['hot_partitions'][0]  # Worst offender
                response += self.technical_advisor.analyze_workload(
                    'hot_partition',
                    {
                        'heat_ratio': hp['heat_ratio'],
                        'ops_per_sec': hp['access_count'] * 10  # Estimate
                    }
                )
                response += "\n\n"
            
            # Migration assessment
            assessment = analysis_results['migration_assessment']
            response += f"Migration risk: {assessment['risk_level'].upper()}\n"
            response += f"Estimated effort: {assessment['estimated_effort_days']} engineering days\n\n"
            
            # ScyllaDB benefits
            response += "With ScyllaDB you'll get:\n"
            for benefit, details in analysis_results['scylladb_benefits'].items():
                if isinstance(details, dict) and 'description' in details:
                    response += f"- {details['description']}\n"
            
            # Add technical insight
            response += "\n" + self.technical_advisor.technical_insight('tablets')
            
            return response
            
        except Exception as e:
            return technical_response(f"Analysis failed: {str(e)}", {'pattern': 'error'})
    
    async def _handle_compare_performance(self, operation: str, itemCount: int = 1000) -> str:
        """Compare performance with real metrics and technical depth."""
        
        # Based on actual ScyllaDB benchmarks from scylladb.com
        if operation == "read":
            dynamodb_metrics = {
                'p99_ms': 10,
                'p50_ms': 5,
                'throttled': int(itemCount * 0.001),  # Some throttling
                'ops': itemCount
            }
            scylladb_metrics = {
                'p99_ms': 3,
                'p50_ms': 1,
                'throttled': 0,
                'ops': itemCount
            }
        elif operation == "write":
            dynamodb_metrics = {
                'p99_ms': 20,
                'p50_ms': 10,
                'throttled': int(itemCount * 0.005),  # More throttling on writes
                'ops': itemCount
            }
            scylladb_metrics = {
                'p99_ms': 5,
                'p50_ms': 2,
                'throttled': 0,
                'ops': itemCount
            }
        else:  # mixed
            dynamodb_metrics = {
                'p99_ms': 15,
                'p50_ms': 7,
                'throttled': int(itemCount * 0.003),
                'ops': itemCount
            }
            scylladb_metrics = {
                'p99_ms': 4,
                'p50_ms': 1.5,
                'throttled': 0,
                'ops': itemCount
            }
        
        response = f"Performance Comparison: {operation} operations on {itemCount:,} items\n\n"
        response += "DynamoDB:\n"
        response += f"  P99 latency: {dynamodb_metrics['p99_ms']}ms\n"
        response += f"  P50 latency: {dynamodb_metrics['p50_ms']}ms\n"
        if dynamodb_metrics['throttled'] > 0:
            response += f"  Throttled requests: {dynamodb_metrics['throttled']}\n"
        
        response += "\nScyllaDB:\n"
        response += f"  P99 latency: {scylladb_metrics['p99_ms']}ms\n"
        response += f"  P50 latency: {scylladb_metrics['p50_ms']}ms\n"
        response += f"  Throttled requests: 0 (hardware limits only)\n"
        
        response += "\n" + self.technical_advisor.explain_performance_delta(
            dynamodb_metrics, scylladb_metrics
        )
        
        # Add architecture insight
        response += "\n\nArchitecture difference:\n"
        response += "- DynamoDB: Request router ‚Üí Storage nodes ‚Üí Java process ‚Üí RocksDB\n"
        response += "- ScyllaDB: Shard-aware client ‚Üí Specific CPU core ‚Üí Direct disk I/O\n"
        response += "\nFewer hops = lower latency."
        
        return response
    
    async def _handle_check_migration(self, code: str, language: str) -> str:
        """Check code compatibility with technical precision."""
        
        compatibility_score = 0.0
        issues = []
        
        # Language-specific patterns
        if language == "python":
            # Check for basic operations
            if "get_item" in code or "put_item" in code:
                compatibility_score += 0.3
            if "query" in code:
                compatibility_score += 0.3
            if "scan" in code:
                compatibility_score += 0.2
                issues.append("scan operations - works but avoid in production")
            
            # Check for complex features
            if "transact_" in code:
                compatibility_score += 0.1
                issues.append("transactions - limited to single partition")
            if "stream" in code.lower():
                compatibility_score += 0.1
                issues.append("streams - use CDC instead")
            
            # If no complex features, boost score
            if len(issues) == 0:
                compatibility_score = 0.95
        
        elif language == "javascript":
            if "getItem" in code or "putItem" in code:
                compatibility_score += 0.3
            if "query" in code:
                compatibility_score += 0.3
            # Similar patterns...
        
        # Build response
        response = self.technical_advisor.migration_assessment({
            'compatibility_score': compatibility_score,
            'issues': issues
        })
        
        # Add code-specific advice
        if "query" in code and "IndexName" in code:
            response += "\n\nGSI detected in code. Each GSI multiplies write costs in DynamoDB."
            response += "\nConsider materialized views in ScyllaDB for better cost efficiency."
        
        return response
    
    async def _handle_cost_estimate(self, reads_per_sec: int, writes_per_sec: int, 
                                   storage_gb: int, item_size_kb: float = 1,
                                   workload_pattern: str = None,
                                   provisioned_capacity: bool = None) -> str:
        """Calculate costs with workload-specific analysis."""
        
        # Try advanced calculator first
        try:
            return calculate_advanced_cost(
                reads_per_sec=reads_per_sec,
                writes_per_sec=writes_per_sec,
                storage_gb=storage_gb,
                item_size_kb=item_size_kb,
                pattern=workload_pattern or 'steady'
            )
        except Exception as e:
            logger.warning(f"Advanced calculator failed: {e}, falling back to simple calculator")
        
        # Determine workload pattern if not specified
        if not workload_pattern:
            read_write_ratio = reads_per_sec / writes_per_sec if writes_per_sec > 0 else float('inf')
            if read_write_ratio > 10:
                workload_pattern = 'read_heavy'
            elif read_write_ratio < 0.5:
                workload_pattern = 'write_heavy'
            else:
                workload_pattern = 'mixed'
        
        # DynamoDB costs (simplified but realistic)
        # On-demand pricing
        read_cost_per_million = 0.25
        write_cost_per_million = 1.25
        
        monthly_reads = reads_per_sec * 86400 * 30
        monthly_writes = writes_per_sec * 86400 * 30
        
        dynamodb_read_cost = (monthly_reads / 1_000_000) * read_cost_per_million
        dynamodb_write_cost = (monthly_writes / 1_000_000) * write_cost_per_million
        dynamodb_storage_cost = storage_gb * 0.25  # $/GB/month
        
        dynamodb_total = dynamodb_read_cost + dynamodb_write_cost + dynamodb_storage_cost
        
        # ScyllaDB costs (i3en.2xlarge as reference)
        # Based on workload, estimate nodes needed
        total_ops = reads_per_sec + writes_per_sec
        
        if total_ops < 30000:
            nodes_needed = 3  # Minimum for production
        elif total_ops < 100000:
            nodes_needed = 6
        else:
            nodes_needed = max(9, (total_ops // 50000) * 3)
        
        instance_cost_per_hour = 0.626  # i3en.2xlarge
        scylladb_compute = nodes_needed * instance_cost_per_hour * 24 * 30
        
        # Add EBS if storage exceeds instance storage
        instance_storage_per_node = 2 * 1900  # 2x 950GB NVMe
        total_instance_storage = nodes_needed * instance_storage_per_node
        
        if storage_gb > total_instance_storage:
            additional_storage_gb = storage_gb - total_instance_storage
            scylladb_storage_cost = additional_storage_gb * 0.10  # EBS gp3
        else:
            scylladb_storage_cost = 0
        
        scylladb_total = scylladb_compute + scylladb_storage_cost
        
        # Calculate savings
        savings_percent = ((dynamodb_total - scylladb_total) / dynamodb_total * 100) if dynamodb_total > 0 else 0
        cost_reduction_factor = dynamodb_total / scylladb_total if scylladb_total > 0 else 0
        
        # Format response
        response = f"üí∞ Cost Analysis for your workload:\n\n"
        response += f"Workload: {reads_per_sec:,} reads/sec, {writes_per_sec:,} writes/sec, {storage_gb:,}GB\n"
        response += f"Pattern: {workload_pattern}\n\n"
        
        response += f"DynamoDB Monthly Costs:\n"
        response += f"  Reads: ${dynamodb_read_cost:,.2f}\n"
        response += f"  Writes: ${dynamodb_write_cost:,.2f}\n"
        response += f"  Storage: ${dynamodb_storage_cost:,.2f}\n"
        response += f"  TOTAL: ${dynamodb_total:,.2f}/month\n\n"
        
        response += f"ScyllaDB Monthly Costs:\n"
        response += f"  Compute: {nodes_needed} x i3en.2xlarge = ${scylladb_compute:,.2f}\n"
        if scylladb_storage_cost > 0:
            response += f"  Additional Storage: ${scylladb_storage_cost:,.2f}\n"
        response += f"  TOTAL: ${scylladb_total:,.2f}/month\n\n"
        
        response += f"üíµ Cost Reduction: {savings_percent:.0f}% ({cost_reduction_factor:.1f}X cheaper)\n\n"
        
        # Add workload-specific analysis
        workload_context = {
            'reads_per_sec': reads_per_sec,
            'writes_per_sec': writes_per_sec,
            'storage_gb': storage_gb,
            'pattern': workload_pattern,
            'provisioned_capacity': provisioned_capacity,
            'avg_item_size_kb': item_size_kb
        }
        
        response += self.technical_advisor.cost_analysis(workload_context)
        
        return response
    
    async def _create_docker_container(self) -> str:
        """Create and start ScyllaDB Docker container."""
        try:
            logger.info("Pulling ScyllaDB image...")
            self.docker_client.images.pull('scylladb/scylla', tag='latest')
            
            logger.info("Creating container...")
            container = self.docker_client.containers.run(
                'scylladb/scylla:latest',
                name='scylladb-mcp',
                ports={
                    '9042/tcp': 9042,  # CQL
                    '8000/tcp': 8000   # Alternator (DynamoDB API)
                },
                environment={
                    'SCYLLA_DEVELOPER_MODE': '1'
                },
                command='--alternator-port 8000 --alternator-write-isolation only_rmw_uses_lwt',
                detach=True,
                remove=False
            )
            
            self.connections.docker_container = container
            return "Docker container 'scylladb-mcp' created and started"
            
        except docker.errors.APIError as e:
            return f"Failed to create container: {str(e)}"
    
    async def _wait_for_scylla(self) -> None:
        """Wait for ScyllaDB to be ready."""
        logger.info("Waiting for ScyllaDB to be ready...")
        
        for i in range(60):  # Wait up to 60 seconds
            try:
                cluster = Cluster(['localhost'], connection_class=AsyncioConnection)
                session = cluster.connect()
                session.shutdown()
                cluster.shutdown()
                logger.info("ScyllaDB is ready!")
                return
            except Exception:
                if i % 10 == 0:
                    logger.info(f"Still waiting... ({i}s)")
                await asyncio.sleep(1)
        
        raise TimeoutError("ScyllaDB failed to start within 60 seconds")
    
    async def _handle_populate_data(self, source: str, table: str, rows: int) -> str:
        """Populate test data with realistic patterns."""
        if not self.connections.scylla:
            return technical_response(
                "Not connected. Run 'connect' first.",
                {'pattern': 'error'}
            )
        
        try:
            # Use demo keyspace
            self.connections.scylla.execute("USE scylladb_demo")
            
            if source == "dynamodb_style":
                # Create DynamoDB-style table
                self.connections.scylla.execute(f"""
                    CREATE TABLE IF NOT EXISTS {table} (
                        pk text,
                        sk text,
                        data text,
                        attributes map<text, text>,
                        ttl int,
                        PRIMARY KEY (pk, sk)
                    )
                """)
                
                # Insert data
                for i in range(rows):
                    pk = f"user_{i % 1000}"  # Create some hot partitions
                    sk = f"item_{i}"
                    data = f"data_{i}" * 10  # Make it somewhat realistic
                    
                    self.connections.scylla.execute(f"""
                        INSERT INTO {table} (pk, sk, data)
                        VALUES ('{pk}', '{sk}', '{data}')
                    """)
                
                response = f"‚úÖ Populated {table} with {rows} DynamoDB-style records\n\n"
                response += "Notice how user_0 through user_999 will create hot partitions? "
                response += "That's your typical DynamoDB anti-pattern right there."
                
                return technical_response(response, {'pattern': 'hot_partition', 
                                                  'metrics': {'heat_ratio': 0.9, 'ops_per_sec': 1000}})
            
            elif source == "ycsb":
                # YCSB workload
                self.connections.scylla.execute(f"""
                    CREATE TABLE IF NOT EXISTS {table} (
                        y_id varchar PRIMARY KEY,
                        field0 varchar, field1 varchar, field2 varchar,
                        field3 varchar, field4 varchar
                    )
                """)
                
                for i in range(rows):
                    self.connections.scylla.execute(f"""
                        INSERT INTO {table} (y_id, field0, field1, field2, field3, field4)
                        VALUES ('user{i}', 'val0_{i}', 'val1_{i}', 'val2_{i}', 'val3_{i}', 'val4_{i}')
                    """)
                
                return technical_response(
                    f"‚úÖ Populated {table} with {rows} YCSB records\n\n"
                    "YCSB - the benchmark everyone games. At least it's consistent.",
                    {'pattern': 'benchmark'}
                )
            
            else:
                return technical_response(
                    f"Source '{source}' not implemented. Pick something that exists.",
                    {'pattern': 'error'}
                )
                
        except Exception as e:
            return technical_response(f"Failed to populate data: {str(e)}", {'pattern': 'error'})
    
    async def _handle_analyze_dynamodb_model(self, data_model: str, requirements: str = None) -> str:
        """Analyze AWS DynamoDB MCP tool output with technical analysis."""
        
        response = "üìã **Analyzing AWS DynamoDB Model for ScyllaDB Migration**\n\n"
        
        # Parse the model for patterns
        hot_partition_risk = False
        gsi_count = data_model.lower().count('global secondary index')
        has_streams = 'streams' in data_model.lower()
        has_transactions = 'transact' in data_model.lower()
        
        # Look for fan-out patterns mentioned in AWS blog
        if 'fan-out' in data_model.lower() or 'massive fan-out' in data_model.lower():
            hot_partition_risk = True
            response += "‚ö†Ô∏è **Fan-out Pattern Detected**\n"
            response += "DynamoDB: Batch limit 25 items ‚Üí Streams ‚Üí Lambda ‚Üí More writes\n"
            response += "Latency stack: Write + Stream lag + Lambda cold start + Fan-out\n"
            response += "ScyllaDB: Single batch write. No external orchestration.\n"
            response += "Latency: One network round-trip.\n\n"
        
        # Check for full-text search
        if 'full-text search' in data_model.lower() or 'opensearch' in data_model.lower():
            response += "üîç **Full-text Search Pattern**\n"
            response += "External search cluster adds complexity and cost. "
            response += "Consider if secondary indexes suffice for your use case.\n\n"
        
        # GSI analysis
        if gsi_count > 0:
            response += f"üìä **{gsi_count} Global Secondary Indexes**\n"
            response += f"Cost multiplication: {gsi_count + 1}√ó write costs\n"
            response += f"Storage multiplication: {gsi_count + 1}√ó storage costs\n"
            response += f"Consistency: Eventually consistent by default\n"
            response += f"ScyllaDB: Materialized views with ~20-30% overhead, strongly consistent\n\n"
        
        # Migration assessment
        response += "üîÑ **Migration Path**\n"
        if has_transactions and has_streams:
            complexity = "Complex"
            effort = "2-4 weeks"
            response += "- Transactions ‚Üí Redesign for single-partition ops\n"
            response += "- Streams ‚Üí Change Data Capture (CDC)\n"
        elif has_transactions or has_streams:
            complexity = "Moderate" 
            effort = "1-2 weeks"
            if has_transactions:
                response += "- Transactions limited to single partition in Alternator\n"
            if has_streams:
                response += "- Use CDC instead of Streams\n"
        else:
            complexity = "Simple"
            effort = "< 1 week"
            response += "- Straightforward port via Alternator API\n"
            response += "- Just change the endpoint\n"
        
        response += f"\nComplexity: {complexity}\n"
        response += f"Effort: {effort}\n\n"
        
        # Cost projection
        response += "üí∞ **Cost Implications**\n"
        if gsi_count > 2:
            response += f"With {gsi_count} GSIs, you're paying {gsi_count + 1}x for every write. "
            response += "ScyllaDB potential savings: 80%+\n"
        elif hot_partition_risk:
            response += "Hot partition patterns require over-provisioning in DynamoDB. "
            response += "ScyllaDB handles bursts to hardware limits. Savings: 60-80%\n"
        else:
            response += "Standard workload. Expect 40-70% savings depending on traffic patterns.\n"
        
        # Anti-patterns
        response += "\n‚ö° **Anti-patterns for ScyllaDB**\n"
        
        if 'uuid' in data_model.lower() and 'partition key' in data_model.lower():
            response += "- UUID as partition key = maximum scatter, zero locality\n"
        
        if 'scan' in data_model.lower() or requirements and 'scan' in requirements.lower():
            response += "- Full table scans. Redesign with proper partition access.\n"
        
        if not hot_partition_risk and not has_transactions:
            response += "- None detected. Clean design.\n"
        
        # Recommendation
        response += "\n‚úÖ **Recommendation**\n"
        if complexity == "Simple":
            response += "Easy migration. Run our cost estimator with your actual traffic numbers. "
            response += "Prepare for significant savings.\n"
        else:
            response += "Migration requires some redesign, but the ROI is clear. "
            response += "We've seen 5X-40X cost reductions in production.\n"
        
        # Add technical analysis
        response = technical_response(response, {
            'pattern': 'aws_model_analysis',
            'has_antipatterns': hot_partition_risk or (gsi_count > 3)
        })
        
        return response
    
    async def run(self):
        """Run the MCP server."""
        logger.info("üöÄ Starting ScyllaDB MCP Server...")
        
        if os.getenv('SCYLLA_IS_DOCKER', 'true').lower() == 'true':
            logger.info("üì¶ Mode: Local Docker Development")
            logger.info("   - Auto-provisioning ScyllaDB container")
            logger.info("   - CQL port: 9042, Alternator port: 8000")
        else:
            logger.info("‚òÅÔ∏è  Mode: ScyllaDB Cloud")
            logger.info("")
            logger.info("‚ö†Ô∏è  ScyllaDB Cloud Setup Tips:")
            logger.info("   1. Choose 'CQL compatible' (NOT 'DynamoDB API only')")
            logger.info("   2. Enable Alternator API in cluster settings")
            logger.info("   3. Isolation Policy: 'Always use LWT' for DynamoDB compatibility")
            logger.info("   4. Enable 'Extract Metrics' for performance monitoring")
            logger.info("   5. This gives you BOTH CQL and DynamoDB APIs")
        
        logger.info("")
        logger.info("‚úÖ Ready for connections from Claude Desktop")
        
        # Create initial connections
        await self.create_connections()
        
        # Run server
        async with stdio_server() as streams:
            await self.server.run(
                streams[0],
                streams[1],
                self.server.create_initialization_options()
            )


def main():
    """Main entry point."""
    server = ScyllaDBMCPServer()
    asyncio.run(server.run())


if __name__ == "__main__":
    main()